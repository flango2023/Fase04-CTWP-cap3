{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação Automática de Grãos de Trigo com Machine Learning\n",
    "\n",
    "**Projeto:** Automatizando a Classificação de Grãos com Machine Learning  \n",
    "**Dataset:** Seeds Dataset - UCI Machine Learning Repository  \n",
    "**Metodologia:** CRISP-DM  \n",
    "**Objetivo:** Classificar variedades de grãos de trigo (Kama, Rosa, Canadian) baseado em características físicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importação de Bibliotecas e Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuração para visualizações\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento do dataset Seeds\n",
    "# O dataset pode ser baixado de: https://archive.ics.uci.edu/dataset/236/seeds\n",
    "\n",
    "# Definindo os nomes das colunas conforme documentação\n",
    "column_names = [\n",
    "    'area',\n",
    "    'perimeter', \n",
    "    'compactness',\n",
    "    'length_kernel',\n",
    "    'width_kernel',\n",
    "    'asymmetry_coefficient',\n",
    "    'length_kernel_groove',\n",
    "    'variety'\n",
    "]\n",
    "\n",
    "# Tentativa de carregar o dataset\n",
    "try:\n",
    "    # Carregando o arquivo (assumindo que está no mesmo diretório)\n",
    "    df = pd.read_csv('seeds_dataset.txt', sep='\\t', names=column_names)\n",
    "    print(f\"Dataset carregado: {df.shape[0]} amostras, {df.shape[1]} características\")\n",
    "except FileNotFoundError:\n",
    "    # Criando dados sintéticos baseados nas características do dataset original\n",
    "    print(\"Arquivo não encontrado. Criando dados sintéticos baseados no Seeds Dataset...\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 210  # 70 amostras por classe\n",
    "    \n",
    "    # Características baseadas nas estatísticas do dataset original\n",
    "    # Kama (classe 1)\n",
    "    kama_data = {\n",
    "        'area': np.random.normal(14.8, 1.2, 70),\n",
    "        'perimeter': np.random.normal(14.2, 0.8, 70),\n",
    "        'compactness': np.random.normal(0.871, 0.023, 70),\n",
    "        'length_kernel': np.random.normal(5.76, 0.32, 70),\n",
    "        'width_kernel': np.random.normal(3.31, 0.22, 70),\n",
    "        'asymmetry_coefficient': np.random.normal(3.12, 0.89, 70),\n",
    "        'length_kernel_groove': np.random.normal(5.22, 0.32, 70),\n",
    "        'variety': [1] * 70\n",
    "    }\n",
    "    \n",
    "    # Rosa (classe 2)\n",
    "    rosa_data = {\n",
    "        'area': np.random.normal(18.7, 1.8, 70),\n",
    "        'perimeter': np.random.normal(16.1, 1.1, 70),\n",
    "        'compactness': np.random.normal(0.886, 0.029, 70),\n",
    "        'length_kernel': np.random.normal(6.17, 0.51, 70),\n",
    "        'width_kernel': np.random.normal(3.58, 0.29, 70),\n",
    "        'asymmetry_coefficient': np.random.normal(2.73, 0.81, 70),\n",
    "        'length_kernel_groove': np.random.normal(5.99, 0.39, 70),\n",
    "        'variety': [2] * 70\n",
    "    }\n",
    "    \n",
    "    # Canadian (classe 3)\n",
    "    canadian_data = {\n",
    "        'area': np.random.normal(12.4, 1.1, 70),\n",
    "        'perimeter': np.random.normal(13.2, 0.7, 70),\n",
    "        'compactness': np.random.normal(0.849, 0.034, 70),\n",
    "        'length_kernel': np.random.normal(5.22, 0.43, 70),\n",
    "        'width_kernel': np.random.normal(2.87, 0.27, 70),\n",
    "        'asymmetry_coefficient': np.random.normal(4.11, 1.18, 70),\n",
    "        'length_kernel_groove': np.random.normal(4.63, 0.39, 70),\n",
    "        'variety': [3] * 70\n",
    "    }\n",
    "    \n",
    "    # Combinando os dados\n",
    "    all_data = {}\n",
    "    for key in kama_data.keys():\n",
    "        all_data[key] = np.concatenate([kama_data[key], rosa_data[key], canadian_data[key]])\n",
    "    \n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    # Embaralhando os dados\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Dados sintéticos criados: {df.shape[0]} amostras, {df.shape[1]} características\")\n",
    "\n",
    "# Exibindo informações básicas do dataset\n",
    "print(\"\\nPrimeiras 5 linhas do dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nInformações do dataset:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nDistribuição das classes:\")\n",
    "print(df['variety'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análise Exploratória dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas descritivas\n",
    "print(\"Estatísticas Descritivas:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Verificação de valores ausentes\n",
    "print(\"\\nValores ausentes por coluna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Mapeamento das variedades para nomes mais descritivos\n",
    "variety_names = {1: 'Kama', 2: 'Rosa', 3: 'Canadian'}\n",
    "df['variety_name'] = df['variety'].map(variety_names)\n",
    "\n",
    "print(\"\\nDistribuição das variedades:\")\n",
    "print(df['variety_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização da distribuição das características\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "features = ['area', 'perimeter', 'compactness', 'length_kernel', \n",
    "           'width_kernel', 'asymmetry_coefficient', 'length_kernel_groove']\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    axes[i].hist(df[feature], bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[i].set_title(f'Distribuição - {feature}')\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel('Frequência')\n",
    "\n",
    "# Removendo o subplot extra\n",
    "axes[7].remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots para identificar outliers\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    axes[i].boxplot(df[feature])\n",
    "    axes[i].set_title(f'Boxplot - {feature}')\n",
    "    axes[i].set_ylabel(feature)\n",
    "\n",
    "axes[7].remove()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de correlação entre características\n",
    "correlation_matrix = df[features].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.2f')\n",
    "plt.title('Matriz de Correlação entre Características')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identificando correlações altas\n",
    "print(\"Correlações altas (> 0.7):\")\n",
    "high_corr = np.where(np.abs(correlation_matrix) > 0.7)\n",
    "for i, j in zip(high_corr[0], high_corr[1]):\n",
    "    if i < j:  # Evitar duplicatas\n",
    "        print(f\"{features[i]} - {features[j]}: {correlation_matrix.iloc[i, j]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficos de dispersão para visualizar separabilidade das classes\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Pares de características mais relevantes\n",
    "feature_pairs = [\n",
    "    ('area', 'perimeter'),\n",
    "    ('length_kernel', 'width_kernel'),\n",
    "    ('compactness', 'asymmetry_coefficient'),\n",
    "    ('area', 'length_kernel'),\n",
    "    ('perimeter', 'width_kernel'),\n",
    "    ('length_kernel_groove', 'asymmetry_coefficient')\n",
    "]\n",
    "\n",
    "colors = ['red', 'blue', 'green']\n",
    "varieties = [1, 2, 3]\n",
    "variety_labels = ['Kama', 'Rosa', 'Canadian']\n",
    "\n",
    "for i, (x_feature, y_feature) in enumerate(feature_pairs):\n",
    "    for j, variety in enumerate(varieties):\n",
    "        subset = df[df['variety'] == variety]\n",
    "        axes[i].scatter(subset[x_feature], subset[y_feature], \n",
    "                       c=colors[j], label=variety_labels[j], alpha=0.6)\n",
    "    \n",
    "    axes[i].set_xlabel(x_feature)\n",
    "    axes[i].set_ylabel(y_feature)\n",
    "    axes[i].set_title(f'{x_feature} vs {y_feature}')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pré-processamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos dados para modelagem\n",
    "X = df[features].copy()\n",
    "y = df['variety'].copy()\n",
    "\n",
    "print(f\"Formato dos dados: X = {X.shape}, y = {y.shape}\")\n",
    "\n",
    "# Verificação da necessidade de normalização\n",
    "print(\"\\nEstatísticas das características (antes da normalização):\")\n",
    "print(X.describe())\n",
    "\n",
    "# Análise da escala das variáveis\n",
    "print(\"\\nRanges das características:\")\n",
    "for feature in features:\n",
    "    min_val = X[feature].min()\n",
    "    max_val = X[feature].max()\n",
    "    range_val = max_val - min_val\n",
    "    print(f\"{feature}: [{min_val:.3f}, {max_val:.3f}] - Range: {range_val:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão dos dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Conjunto de treinamento: {X_train.shape[0]} amostras\")\n",
    "print(f\"Conjunto de teste: {X_test.shape[0]} amostras\")\n",
    "\n",
    "# Verificando a distribuição das classes nos conjuntos\n",
    "print(\"\\nDistribuição das classes no conjunto de treinamento:\")\n",
    "print(y_train.value_counts().sort_index())\n",
    "\n",
    "print(\"\\nDistribuição das classes no conjunto de teste:\")\n",
    "print(y_test.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convertendo de volta para DataFrame para facilitar análise\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=features)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=features)\n",
    "\n",
    "print(\"Estatísticas após normalização (conjunto de treinamento):\")\n",
    "print(X_train_scaled_df.describe())\n",
    "\n",
    "print(\"\\nNormalização aplicada com sucesso\")\n",
    "print(\"Média próxima de 0 e desvio padrão próximo de 1 confirmam a padronização\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementação e Comparação de Algoritmos de Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os modelos de classificação\n",
    "models = {\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'SVM': SVC(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)\n",
    "}\n",
    "\n",
    "# Dicionário para armazenar resultados\n",
    "results = {}\n",
    "\n",
    "print(\"Treinando e avaliando modelos...\\n\")\n",
    "\n",
    "# Treinamento e avaliação de cada modelo\n",
    "for name, model in models.items():\n",
    "    print(f\"Treinando {name}...\")\n",
    "    \n",
    "    # Treinamento\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predições\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Métricas\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Validação cruzada\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "    \n",
    "    # Armazenando resultados\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"Acurácia no teste: {accuracy:.4f}\")\n",
    "    print(f\"Validação cruzada: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparação visual dos resultados\n",
    "model_names = list(results.keys())\n",
    "accuracies = [results[name]['accuracy'] for name in model_names]\n",
    "cv_means = [results[name]['cv_mean'] for name in model_names]\n",
    "cv_stds = [results[name]['cv_std'] for name in model_names]\n",
    "\n",
    "# Gráfico de barras comparativo\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Acurácia no teste\n",
    "bars1 = ax1.bar(model_names, accuracies, color='skyblue', alpha=0.7)\n",
    "ax1.set_title('Acurácia no Conjunto de Teste')\n",
    "ax1.set_ylabel('Acurácia')\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Adicionando valores nas barras\n",
    "for bar, acc in zip(bars1, accuracies):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Validação cruzada\n",
    "bars2 = ax2.bar(model_names, cv_means, yerr=cv_stds, \n",
    "                color='lightcoral', alpha=0.7, capsize=5)\n",
    "ax2.set_title('Validação Cruzada (5-fold)')\n",
    "ax2.set_ylabel('Acurácia Média')\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Adicionando valores nas barras\n",
    "for bar, mean_val in zip(bars2, cv_means):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{mean_val:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tabela resumo dos resultados\n",
    "results_df = pd.DataFrame({\n",
    "    'Modelo': model_names,\n",
    "    'Acurácia Teste': [f\"{acc:.4f}\" for acc in accuracies],\n",
    "    'CV Média': [f\"{mean:.4f}\" for mean in cv_means],\n",
    "    'CV Desvio': [f\"{std:.4f}\" for std in cv_stds]\n",
    "})\n",
    "\n",
    "print(\"\\nResumo dos Resultados:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relatórios de classificação detalhados\n",
    "variety_labels = ['Kama', 'Rosa', 'Canadian']\n",
    "\n",
    "for name in model_names:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"RELATÓRIO DETALHADO - {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    y_pred = results[name]['predictions']\n",
    "    \n",
    "    # Relatório de classificação\n",
    "    print(\"\\nRelatório de Classificação:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=variety_labels))\n",
    "    \n",
    "    # Matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=variety_labels, yticklabels=variety_labels)\n",
    "    plt.title(f'Matriz de Confusão - {name}')\n",
    "    plt.xlabel('Predito')\n",
    "    plt.ylabel('Real')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Otimização de Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os hiperparâmetros para otimização\n",
    "param_grids = {\n",
    "    'KNN': {\n",
    "        'n_neighbors': [3, 5, 7, 9, 11],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'solver': ['liblinear', 'lbfgs'],\n",
    "        'penalty': ['l2']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Naive Bayes não tem hiperparâmetros significativos para otimizar\n",
    "optimized_results = {}\n",
    "\n",
    "print(\"Iniciando otimização de hiperparâmetros...\\n\")\n",
    "\n",
    "for name in param_grids.keys():\n",
    "    print(f\"Otimizando {name}...\")\n",
    "    \n",
    "    # Grid Search\n",
    "    grid_search = GridSearchCV(\n",
    "        models[name], \n",
    "        param_grids[name], \n",
    "        cv=5, \n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Melhor modelo\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Predições com o modelo otimizado\n",
    "    y_pred_optimized = best_model.predict(X_test_scaled)\n",
    "    accuracy_optimized = accuracy_score(y_test, y_pred_optimized)\n",
    "    \n",
    "    # Validação cruzada do modelo otimizado\n",
    "    cv_scores_optimized = cross_val_score(best_model, X_train_scaled, y_train, cv=5)\n",
    "    \n",
    "    optimized_results[name] = {\n",
    "        'best_model': best_model,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_cv_score': grid_search.best_score_,\n",
    "        'test_accuracy': accuracy_optimized,\n",
    "        'cv_mean': cv_scores_optimized.mean(),\n",
    "        'cv_std': cv_scores_optimized.std(),\n",
    "        'predictions': y_pred_optimized\n",
    "    }\n",
    "    \n",
    "    print(f\"Melhores parâmetros: {grid_search.best_params_}\")\n",
    "    print(f\"Melhor score CV: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Acurácia no teste: {accuracy_optimized:.4f}\")\n",
    "    \n",
    "    # Comparação com modelo original\n",
    "    improvement = accuracy_optimized - results[name]['accuracy']\n",
    "    print(f\"Melhoria: {improvement:+.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Adicionando Naive Bayes (sem otimização)\n",
    "optimized_results['Naive Bayes'] = {\n",
    "    'best_model': results['Naive Bayes']['model'],\n",
    "    'best_params': 'Não aplicável',\n",
    "    'test_accuracy': results['Naive Bayes']['accuracy'],\n",
    "    'cv_mean': results['Naive Bayes']['cv_mean'],\n",
    "    'cv_std': results['Naive Bayes']['cv_std'],\n",
    "    'predictions': results['Naive Bayes']['predictions']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparação antes e depois da otimização\n",
    "comparison_data = []\n",
    "\n",
    "for name in model_names:\n",
    "    original_acc = results[name]['accuracy']\n",
    "    \n",
    "    if name in optimized_results:\n",
    "        optimized_acc = optimized_results[name]['test_accuracy']\n",
    "        improvement = optimized_acc - original_acc\n",
    "    else:\n",
    "        optimized_acc = original_acc\n",
    "        improvement = 0\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Modelo': name,\n",
    "        'Acurácia Original': f\"{original_acc:.4f}\",\n",
    "        'Acurácia Otimizada': f\"{optimized_acc:.4f}\",\n",
    "        'Melhoria': f\"{improvement:+.4f}\"\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nComparação: Original vs Otimizado\")\n",
    "print(\"=\" * 50)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualização da comparação\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "original_accs = [results[name]['accuracy'] for name in model_names]\n",
    "optimized_accs = [optimized_results.get(name, results[name])['test_accuracy'] for name in model_names]\n",
    "\n",
    "bars1 = ax.bar(x - width/2, original_accs, width, label='Original', alpha=0.7)\n",
    "bars2 = ax.bar(x + width/2, optimized_accs, width, label='Otimizado', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Modelos')\n",
    "ax.set_ylabel('Acurácia')\n",
    "ax.set_title('Comparação: Modelos Originais vs Otimizados')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_names, rotation=45)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# Adicionando valores nas barras\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Análise e Interpretação dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificando o melhor modelo\n",
    "best_model_name = max(optimized_results.keys(), \n",
    "                     key=lambda x: optimized_results[x]['test_accuracy'])\n",
    "best_model_info = optimized_results[best_model_name]\n",
    "\n",
    "print(f\"MELHOR MODELO: {best_model_name}\")\n",
    "print(f\"Acurácia no teste: {best_model_info['test_accuracy']:.4f}\")\n",
    "print(f\"Validação cruzada: {best_model_info['cv_mean']:.4f} (+/- {best_model_info['cv_std']*2:.4f})\")\n",
    "\n",
    "if 'best_params' in best_model_info and best_model_info['best_params'] != 'Não aplicável':\n",
    "    print(f\"Melhores parâmetros: {best_model_info['best_params']}\")\n",
    "\n",
    "# Análise detalhada do melhor modelo\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ANÁLISE DETALHADA DO MELHOR MODELO: {best_model_name}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "best_predictions = best_model_info['predictions']\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, best_predictions, target_names=variety_labels))\n",
    "\n",
    "# Matriz de confusão do melhor modelo\n",
    "cm_best = confusion_matrix(y_test, best_predictions)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_best, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=variety_labels, yticklabels=variety_labels)\n",
    "plt.title(f'Matriz de Confusão - {best_model_name} (Melhor Modelo)')\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Real')\n",
    "plt.show()\n",
    "\n",
    "# Análise de erros\n",
    "errors = y_test != best_predictions\n",
    "error_count = errors.sum()\n",
    "total_count = len(y_test)\n",
    "\n",
    "print(f\"\\nAnálise de Erros:\")\n",
    "print(f\"Total de erros: {error_count} de {total_count} amostras\")\n",
    "print(f\"Taxa de erro: {error_count/total_count:.4f}\")\n",
    "\n",
    "if error_count > 0:\n",
    "    print(\"\\nAmostras classificadas incorretamente:\")\n",
    "    error_indices = np.where(errors)[0]\n",
    "    for idx in error_indices:\n",
    "        actual = y_test.iloc[idx]\n",
    "        predicted = best_predictions[idx]\n",
    "        print(f\"Amostra {idx}: Real = {variety_names[actual]}, Predito = {variety_names[predicted]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise da importância das características (para modelos que suportam)\n",
    "if best_model_name == 'Random Forest':\n",
    "    feature_importance = best_model_info['best_model'].feature_importances_\n",
    "    \n",
    "    # Criando DataFrame para visualização\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Característica': features,\n",
    "        'Importância': feature_importance\n",
    "    }).sort_values('Importância', ascending=False)\n",
    "    \n",
    "    print(\"\\nImportância das Características (Random Forest):\")\n",
    "    print(importance_df.to_string(index=False))\n",
    "    \n",
    "    # Visualização\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(importance_df['Característica'], importance_df['Importância'])\n",
    "    plt.title('Importância das Características - Random Forest')\n",
    "    plt.xlabel('Características')\n",
    "    plt.ylabel('Importância')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Adicionando valores nas barras\n",
    "    for bar, importance in zip(bars, importance_df['Importância']):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                f'{importance:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "elif best_model_name == 'Logistic Regression':\n",
    "    # Coeficientes da regressão logística\n",
    "    coefficients = best_model_info['best_model'].coef_\n",
    "    \n",
    "    print(\"\\nCoeficientes da Regressão Logística:\")\n",
    "    for i, variety in enumerate(['Kama', 'Rosa', 'Canadian']):\n",
    "        print(f\"\\n{variety}:\")\n",
    "        coef_df = pd.DataFrame({\n",
    "            'Característica': features,\n",
    "            'Coeficiente': coefficients[i]\n",
    "        }).sort_values('Coeficiente', key=abs, ascending=False)\n",
    "        print(coef_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insights e conclusões\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INSIGHTS E CONCLUSÕES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. PERFORMANCE DOS MODELOS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Ranking dos modelos\n",
    "model_ranking = sorted(optimized_results.items(), \n",
    "                      key=lambda x: x[1]['test_accuracy'], reverse=True)\n",
    "\n",
    "for i, (name, info) in enumerate(model_ranking, 1):\n",
    "    print(f\"{i}. {name}: {info['test_accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\n2. ANÁLISE DAS CARACTERÍSTICAS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Características mais correlacionadas\n",
    "high_corr_pairs = []\n",
    "for i in range(len(features)):\n",
    "    for j in range(i+1, len(features)):\n",
    "        corr_val = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.7:\n",
    "            high_corr_pairs.append((features[i], features[j], corr_val))\n",
    "\n",
    "if high_corr_pairs:\n",
    "    print(\"Características altamente correlacionadas:\")\n",
    "    for feat1, feat2, corr in high_corr_pairs:\n",
    "        print(f\"  {feat1} - {feat2}: {corr:.3f}\")\n",
    "else:\n",
    "    print(\"Não foram encontradas correlações muito altas entre características.\")\n",
    "\n",
    "print(\"\\n3. SEPARABILIDADE DAS CLASSES:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Análise da distribuição das classes\n",
    "class_stats = df.groupby('variety')[features].mean()\n",
    "print(\"Médias das características por classe:\")\n",
    "print(class_stats.round(3))\n",
    "\n",
    "print(\"\\n4. RECOMENDAÇÕES PARA APLICAÇÃO PRÁTICA:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "best_accuracy = best_model_info['test_accuracy']\n",
    "\n",
    "if best_accuracy >= 0.95:\n",
    "    print(\"• Excelente performance - Modelo pronto para produção\")\n",
    "elif best_accuracy >= 0.90:\n",
    "    print(\"• Boa performance - Adequado para uso com monitoramento\")\n",
    "elif best_accuracy >= 0.85:\n",
    "    print(\"• Performance moderada - Considerar mais dados ou features\")\n",
    "else:\n",
    "    print(\"• Performance baixa - Necessita melhorias significativas\")\n",
    "\n",
    "print(f\"• Modelo recomendado: {best_model_name}\")\n",
    "print(f\"• Acurácia esperada: {best_accuracy:.1%}\")\n",
    "print(\"• Aplicação: Classificação automática de grãos de trigo\")\n",
    "print(\"• Benefícios: Redução de tempo e erro humano na classificação\")\n",
    "\n",
    "print(\"\\n5. LIMITAÇÕES E CONSIDERAÇÕES:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"• Dataset relativamente pequeno (210 amostras)\")\n",
    "print(\"• Necessidade de validação com dados de diferentes origens\")\n",
    "print(\"• Importância da calibração dos equipamentos de medição\")\n",
    "print(\"• Consideração de fatores ambientais na coleta\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROJETO CONCLUÍDO COM SUCESSO\")\n",
    "print(\"Metodologia CRISP-DM aplicada integralmente\")\n",
    "print(\"Sistema de classificação automática desenvolvido e validado\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}